"""–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–±-–∫–∞–º–µ—Ä–æ–π."""
import logging
from pathlib import Path
from typing import List, Optional
from datetime import datetime

import cv2
import numpy as np
from PySide6.QtCore import QObject, Signal, QThread, QMutex
from PySide6.QtGui import QImage

from client.src.config import get_config

logger = logging.getLogger(__name__)


class CameraWorker(QThread):
    """–ü–æ—Ç–æ–∫ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã."""
    frame_ready = Signal(QImage)
    error = Signal(str)

    def __init__(self, camera_index: int, resolution: tuple, fps: int):
        super().__init__()
        self.camera_index = camera_index
        self.resolution = resolution
        self.fps = fps
        self.running = False
        self.capture = None
        self.mutex = QMutex()

        # –î–ª—è –∑–∞–ø–∏—Å–∏
        self.recording = False
        self.video_writer = None
        self.output_path = None
        
        # –î–ª—è —Å–Ω–∞–ø—à–æ—Ç–æ–≤
        self.last_frame = None
        self.last_frame_mutex = QMutex()

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∑–∞—Ö–≤–∞—Ç–∞."""
        if self.camera_index == -1:
            logger.info("Starting CameraWorker in MOCK mode")
            self.capture = None
        else:
            # –í—ã–±–æ—Ä –±—ç–∫–µ–Ω–¥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –û–°
            import platform
            system = platform.system()
            backend = cv2.CAP_ANY
            
            if system == "Windows":
                backend = cv2.CAP_DSHOW
            elif system == "Linux":
                backend = cv2.CAP_V4L2
                
            logger.info(f"Opening camera {self.camera_index} with backend {backend} (System: {system})")
            self.capture = cv2.VideoCapture(self.camera_index, backend)
            
            if not self.capture.isOpened():
                # Fallback to ANY if specific backend fails
                logger.warning(f"Failed to open with backend {backend}, trying CAP_ANY")
                self.capture = cv2.VideoCapture(self.camera_index, cv2.CAP_ANY)
                
            if not self.capture.isOpened():
                self.error.emit("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
                return

            self.capture.set(cv2.CAP_PROP_FRAME_WIDTH, self.resolution[0])
            self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, self.resolution[1])
            self.capture.set(cv2.CAP_PROP_FPS, self.fps)

        self.running = True

        while self.running:
            if self.camera_index == -1:
                # Mock frame generation
                frame = np.zeros((self.resolution[1], self.resolution[0], 3), dtype=np.uint8)
                # Random noise background
                noise = np.random.randint(0, 256, (self.resolution[1], self.resolution[0], 3), dtype=np.uint8)
                frame = cv2.addWeighted(frame, 0.5, noise, 0.5, 0)
                
                # Add timestamp text
                cv2.putText(
                    frame, 
                    f"NO CAMERA FOUND (MOCK)", 
                    (50, 50), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    1, 
                    (0, 0, 255), 
                    2
                )
                cv2.putText(
                    frame, 
                    f"{datetime.now().strftime('%H:%M:%S')}", 
                    (50, 100), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    1, 
                    (0, 255, 0), 
                    2
                )
                
                # Add recording indicator
                if self.recording:
                    cv2.circle(frame, (30, 30), 10, (0, 0, 255), -1)
            else:
                ret, frame = self.capture.read()
                if not ret:
                    continue

            # –ó–∞–ø–∏—Å–∞—Ç—å –∫–∞–¥—Ä –µ—Å–ª–∏ –∏–¥—ë—Ç –∑–∞–ø–∏—Å—å (protected by mutex)
            self.mutex.lock()
            try:
                if self.recording and self.video_writer:
                    self.video_writer.write(frame)
            finally:
                self.mutex.unlock()
                
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–∞–¥—Ä –¥–ª—è —Å–Ω–∞–ø—à–æ—Ç–æ–≤
            self.last_frame_mutex.lock()
            self.last_frame = frame.copy()
            self.last_frame_mutex.unlock()

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ QImage –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = rgb_frame.shape
            bytes_per_line = ch * w
            q_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            self.frame_ready.emit(q_image.copy())

            # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å FPS
            self.msleep(int(1000 / self.fps))

        # –û—á–∏—Å—Ç–∫–∞
        self.mutex.lock()
        try:
            if self.video_writer:
                self.video_writer.release()
                self.video_writer = None
        finally:
            self.mutex.unlock()
            
        if self.capture:
            self.capture.release()
        logger.info("Camera worker stopped")

    def start_recording(self, output_path: Path):
        """–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≤–∏–¥–µ–æ."""
        self.mutex.lock()
        config = get_config()
        codec = cv2.VideoWriter_fourcc(*config["camera"]["codec"])
        self.output_path = output_path
        self.video_writer = cv2.VideoWriter(
            str(output_path),
            codec,
            self.fps,
            self.resolution
        )
        self.recording = True
        self.mutex.unlock()
        logger.info(f"Started recording to {output_path}")

    def stop_recording(self) -> Optional[Path]:
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ –≤–µ—Ä–Ω—É—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É."""
        self.mutex.lock()
        self.recording = False
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None
        path = self.output_path
        self.output_path = None
        self.mutex.unlock()
        logger.info(f"Stopped recording: {path}")
        return path

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞—Ö–≤–∞—Ç."""
        self.running = False
        self.wait()

    def get_last_frame_jpeg(self) -> Optional[bytes]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–∞–¥—Ä –≤ —Ñ–æ—Ä–º–∞—Ç–µ JPEG."""
        self.last_frame_mutex.lock()
        try:
            if self.last_frame is None:
                return None
            _, buffer = cv2.imencode('.jpg', self.last_frame)
            return buffer.tobytes()
        finally:
            self.last_frame_mutex.unlock()


class CameraService(QObject):
    """–°–µ—Ä–≤–∏—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–∞–º–µ—Ä–æ–π."""
    frame_ready = Signal(QImage)
    recording_started = Signal()
    recording_stopped = Signal(str)  # –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    recording_size_updated = Signal(int)  # —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö
    recording_limit_exceeded = Signal(str)  # –ø—Ä–∏—á–∏–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    error = Signal(str)

    def __init__(self):
        super().__init__()
        config = get_config()
        self.camera_index = config["camera"]["default_index"]
        self.resolution = tuple(config["camera"]["resolution"])
        self.fps = config["camera"]["fps"]
        self.container = config["camera"]["container"]
        self.max_duration_seconds = config["camera"].get("max_duration_seconds", 300)
        self.max_size_mb = config["camera"].get("max_size_mb", 100)
        
        self.worker: Optional[CameraWorker] = None
        self.current_video_path: Optional[Path] = None
        self.recording_start_time: Optional[datetime] = None
        
        # –¢–∞–π–º–µ—Ä –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –≤–∏–¥–µ–æ
        from PySide6.QtCore import QTimer
        self.size_update_timer = QTimer(self)
        self.size_update_timer.timeout.connect(self._update_video_size)
        self.size_update_timer.setInterval(1000)  # –ö–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É

    @staticmethod
    def list_available_cameras(max_check: int = 5) -> List[int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞–º–µ—Ä."""
        available = []
        import platform
        system = platform.system()
        backend = cv2.CAP_ANY
        
        if system == "Windows":
            backend = cv2.CAP_DSHOW
        elif system == "Linux":
            backend = cv2.CAP_V4L2
            
        for i in range(max_check):
            cap = cv2.VideoCapture(i, backend)
            if cap.isOpened():
                available.append(i)
                cap.release()
            else:
                # Try fallback
                cap = cv2.VideoCapture(i, cv2.CAP_ANY)
                if cap.isOpened():
                    available.append(i)
                    cap.release()
                    
        return available

    def start_preview(self, camera_index: Optional[int] = None):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–µ–≤—å—é —Å –∫–∞–º–µ—Ä—ã."""
        if self.worker and self.worker.isRunning():
            self.stop_preview()

        index = camera_index if camera_index is not None else self.camera_index
        
        # Check if camera is available, otherwise use mock
        if index != -1:
            cap = cv2.VideoCapture(index)
            is_opened = cap.isOpened()
            cap.release()
            
            if not is_opened:
                logger.warning(f"Camera {index} not found. Switching to MOCK mode.")
                index = -1
        
        self.worker = CameraWorker(index, self.resolution, self.fps)
        self.worker.frame_ready.connect(self.frame_ready.emit)
        self.worker.error.connect(self.error.emit)
        self.worker.start()

    def stop_preview(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–µ–≤—å—é."""
        if self.worker:
            self.worker.stop()
            self.worker = None

    def start_recording(self, output_dir: Path) -> Path:
        """–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≤–∏–¥–µ–æ."""
        if not self.worker:
            raise RuntimeError("Camera not started")

        output_dir.mkdir(parents=True, exist_ok=True)
        filename = f"video_{datetime.now().strftime('%H%M%S')}.{self.container}"
        output_path = output_dir / filename

        self.worker.start_recording(output_path)
        self.current_video_path = output_path
        self.recording_start_time = datetime.now()
        self.size_update_timer.start()
        self.recording_started.emit()
        return output_path

    def stop_recording(self) -> Optional[Path]:
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ –≤–µ—Ä–Ω—É—Ç—å –ø—É—Ç—å."""
        if not self.worker:
            return None

        self.size_update_timer.stop()
        path = self.worker.stop_recording()
        self.current_video_path = None
        self.recording_start_time = None
        if path:
            self.recording_stopped.emit(str(path))
        return path

    def is_recording(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–¥—ë—Ç –ª–∏ –∑–∞–ø–∏—Å—å."""
        return self.worker is not None and self.worker.recording
    
    def _update_video_size(self):
        """–û–±–Ω–æ–≤–∏—Ç—å —Ä–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–∏–≥–Ω–∞–ª."""
        if self.current_video_path and self.current_video_path.exists():
            try:
                size = self.current_video_path.stat().st_size
                self.recording_size_updated.emit(size)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤
                if self.recording_start_time:
                    elapsed = (datetime.now() - self.recording_start_time).total_seconds()
                    size_mb = size / (1024 * 1024)
                    
                    if elapsed >= self.max_duration_seconds:
                        logger.info(f"Recording stopped: duration limit exceeded ({elapsed:.1f}s >= {self.max_duration_seconds}s)")
                        self.recording_limit_exceeded.emit(
                            f"‚è± –ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞\n\n–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏\n({int(elapsed)}—Å / {self.max_duration_seconds}—Å)"
                        )
                        self.stop_recording()
                    elif size_mb >= self.max_size_mb:
                        logger.info(f"Recording stopped: size limit exceeded ({size_mb:.1f}MB >= {self.max_size_mb}MB)")
                        self.recording_limit_exceeded.emit(
                            f"üíæ –ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞\n\n–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞\n({size_mb:.1f}MB / {self.max_size_mb}MB)"
                        )
                        self.stop_recording()
            except Exception as e:
                logger.warning(f"Failed to get video size: {e}")

    def take_snapshot(self) -> Optional[bytes]:
        """–°–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞."""
        if not self.worker:
            return None
            
        # We need to get the current frame from the worker
        # Since worker emits signals, we can't easily "pull" the frame synchronously without storing it
        # But for a snapshot, we can just capture one frame from the device if we are in the main thread, 
        # OR better: let the worker store the last frame and access it safely.
        
        # However, accessing worker state from main thread requires care.
        # Let's add a request_snapshot method to worker or just grab a frame directly if possible?
        # Direct capture is bad if camera is busy.
        
        # Simplest approach: The worker is already running. We can add a 'last_frame' property to worker protected by mutex.
        return self.worker.get_last_frame_jpeg()
